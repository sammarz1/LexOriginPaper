{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "821853ac-a14f-4dc4-a4ac-7da3c15a4a0d",
   "metadata": {},
   "source": [
    "- Spain: La razón, 2o minutos\n",
    "- Mexico: el universo, \n",
    "- Colombia: elheraldo, El Colombiano\n",
    "- Argentina: la nacion, pagina/12\n",
    "- Chile: diario de concepcion, biobiochile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e8b7dd1d-5d24-41da-893c-89c40a1787bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15f4a0-89a4-4545-a6b9-200ee9773d9c",
   "metadata": {},
   "source": [
    "# Spain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf5d30-1080-444e-a6fc-daef667a7ed2",
   "metadata": {},
   "source": [
    "## El País"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ae94cf-8070-4f1e-ab9d-f0822aece0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.larazon.es'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5f2e18-04ce-426d-82f1-f3ab89eacd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.larazon.es/internacional/', 'https://www.larazon.es/sociedad/', 'https://www.larazon.es/espana/', \n",
    "         'https://www.larazon.es/economia/','https://www.larazon.es/cultura/', 'https://elpais.com/salud/', 'https://elpais.com/gente/' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5e82e2e-0d73-4f98-8e0b-7a28d2f7fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        article_links = []\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            title_elements = soup.find_all(class_='article__title')\n",
    "\n",
    "            for element in title_elements:\n",
    "                a_tag = element.find('a', href=True)\n",
    "                if a_tag:\n",
    "                    href = a_tag['href'].strip()\n",
    "                    if href.startswith('/') and '/autor/' not in href.lower():\n",
    "                        article_links.append(f\"https://www.larazon.es{href}\")\n",
    "                    elif href.startswith('http') and '/autor/' not in href.lower():\n",
    "                        article_links.append(href)\n",
    "\n",
    "            # Filter out unwanted links and remove duplicates\n",
    "            article_links = list(set(\n",
    "                filter(lambda h: h.startswith('http') and not h.startswith('https://promociones.larazon.es/'), article_links)\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch page: {url} (Status code: {response.status_code})\")\n",
    "        return article_links\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "            content_div = art_soup.select_one('div.article-main__content')\n",
    "            if content_div:\n",
    "                paragraphs = content_div.find_all('p')\n",
    "                return \"\\n\".join(p.get_text(strip=True) for p in paragraphs)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4578fe61-22ec-4907-9ad1-a8c946999e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: https://www.larazon.es/internacional/\n",
      "finished: https://www.larazon.es/sociedad/\n",
      "finished: https://www.larazon.es/espana/\n",
      "finished: https://www.larazon.es/economia/\n",
      "finished: https://www.larazon.es/cultura/\n",
      "❌ Failed to fetch page: https://elpais.com/salud/ (Status code: 404)\n",
      "finished: https://elpais.com/salud/\n",
      "finished: https://elpais.com/gente/\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(3,5))\n",
    "    print(f'finished: {tema}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff9b984e-4e41-4122-b7da-a2a5e3500c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Spain']*len(data),\n",
    "    'FUENTE': ['LaRazon']*len(data)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edf28a9d-ab82-4676-8d23-bcd2a8204e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_la_razon.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913a907-7e7b-43dc-863d-cb0e1e839a2a",
   "metadata": {},
   "source": [
    "## 20 Minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86050727-f4ef-4662-9358-1f44346f1e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.20minutos.es'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c057e1cd-9a18-48f3-a0d5-f20e28f522c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.20minutos.es/nacional/', 'https://www.20minutos.es/internacional/', 'https://www.20minutos.es/lainformacion/', \n",
    "         'https://www.20minutos.es/deportes/','https://www.20minutos.es/gente/' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0604797-7242-4ab7-987e-a95b7873661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            title_elements = soup.find_all(class_='media-content')\n",
    "        \n",
    "            for element in title_elements:\n",
    "                a_tag = element.find('a', href=True)\n",
    "                if a_tag:\n",
    "                    href = a_tag['href'].strip()\n",
    "                    article_links.append(href)\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch page: {url} (Status code: {response.status_code})\")\n",
    "        return article_links\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "            \n",
    "            # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='paragraph')\n",
    "            return \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0436728e-23a4-4076-8b89-6f60619d5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: https://www.20minutos.es/nacional/\n",
      "finished: https://www.20minutos.es/internacional/\n",
      "finished: https://www.20minutos.es/lainformacion/\n",
      "finished: https://www.20minutos.es/deportes/\n",
      "finished: https://www.20minutos.es/gente/\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44c26a99-0fd2-4a15-a5b1-7f213157cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Spain']*len(data),\n",
    "    'FUENTE': ['20minutos']*len(data)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "556a66bc-ffea-4369-bf4e-7f8d75532f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['TEXTO'].str.strip() != '']\n",
    "\n",
    "df.to_csv('20mins.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951e522-5b0b-49d3-bac0-0083115956d5",
   "metadata": {},
   "source": [
    "# Mexico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b96ae-07a9-485c-8167-7a0a43cd1817",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## el universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55ed2314-fd10-43b5-ba55-fd24648fa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.eluniversal.com.mx/nacion', 'https://www.eluniversal.com.mx/mundo', 'https://www.eluniversal.com.mx/cartera', \n",
    "         'https://www.eluniversal.com.mx/deportes/', 'https://www.eluniversal.com.mx/cultura/']\n",
    "\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <a> tags with a unique identifier in the class\n",
    "            a_tags = soup.find_all('a', class_='cards-story-opener-fr')\n",
    "            \n",
    "            for a in a_tags:\n",
    "                href = a.get('href')\n",
    "                if href:\n",
    "                    # If href is relative, you might want to add the domain\n",
    "                    if href.startswith('/'):\n",
    "                        href = 'https://www.eluniversal.com.mx' + href\n",
    "                    article_links.append(href)\n",
    "            return article_links\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return article_links\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "                \n",
    "                # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='sc__font-paragraph')\n",
    "            joined_paragraph = ' '.join(p.get_text(strip=True) for p in paragraphs)       \n",
    "        return joined_paragraph\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff8afba4-d230-45bf-878e-83875a6525b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: https://www.eluniversal.com.mx/nacion\n",
      "finished: https://www.eluniversal.com.mx/mundo\n",
      "finished: https://www.eluniversal.com.mx/cartera\n",
      "finished: https://www.eluniversal.com.mx/deportes/\n",
      "finished: https://www.eluniversal.com.mx/cultura/\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1922d5ec-fd47-4590-83c2-ee64ed626899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Mexico']*len(data),\n",
    "    'FUENTE': ['ElUniversal']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8f60c92-7ce2-423c-9afb-e3dd80b55f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_el_universo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e9ee5-2eeb-4880-8387-2e4b8004f98c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## La Jornada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd264754-c6e2-45dc-b960-0e7bfaa15b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.jornada.com.mx'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97e094a4-0e2d-4c10-af84-6a2862be851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.jornada.com.mx/categoria/politica', 'https://www.jornada.com.mx/categoria/economia', 'https://www.jornada.com.mx/categoria/mundo', \n",
    "         'https://www.jornada.com.mx/categoria/estados', 'https://www.jornada.com.mx/categoria/cultura', 'https://www.jornada.com.mx/categoria/deportes', 'https://www.jornada.com.mx/categoria/ciencia-y-tecnologia']\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <h3> tags with the specified class\n",
    "            h3_tags = soup.find_all('h3', class_='nota-titulo mb-1')\n",
    "            \n",
    "            for h3 in h3_tags:\n",
    "                a_tag = h3.find('a')  # Find the <a> inside the <h3>\n",
    "                if a_tag and a_tag.get('href'):\n",
    "                    href = a_tag['href']\n",
    "                    article_links.append(href)\n",
    "            return article_links\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return article_links\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "                \n",
    "                # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='nota-justify')\n",
    "            joined_paragraph = ' '.join(p.get_text(strip=True) for p in paragraphs)       \n",
    "        return joined_paragraph\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58940197-f122-4df5-843b-6d7545c5622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: https://www.jornada.com.mx/categoria/politica\n",
      "finished: https://www.jornada.com.mx/categoria/economia\n",
      "finished: https://www.jornada.com.mx/categoria/mundo\n",
      "finished: https://www.jornada.com.mx/categoria/estados\n",
      "finished: https://www.jornada.com.mx/categoria/cultura\n",
      "finished: https://www.jornada.com.mx/categoria/deportes\n",
      "finished: https://www.jornada.com.mx/categoria/ciencia-y-tecnologia\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4c11996-f688-424d-9611-d4a091492bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Mexico']*len(data),\n",
    "    'FUENTE': ['LaJornada']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "492b8b4a-b779-4f68-bed1-70f2d479293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_LaJornada.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5562b-6f1d-4f3f-b0c3-b96e43c35327",
   "metadata": {},
   "source": [
    "# Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f38e844f-4cdc-4ff1-9078-f0e87196a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.elheraldo.co'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "634877d2-84ca-4ac8-8066-7b0e459ada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.elheraldo.co/atlantico/', 'https://www.elheraldo.co/deportes/', 'https://www.elheraldo.co/judicial/', \n",
    "         'https://www.elheraldo.co/economia/', 'https://www.elheraldo.co/region/']\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <h3> tags with the specified class\n",
    "            h3_tags = soup.find_all(\n",
    "                'h3', \n",
    "                class_='ingl-heading elheraldo__StyledHeadline-sc-1hpknk8-4 kUEUzH ingl-story-card__headline'\n",
    "            )\n",
    "            \n",
    "            for h3 in h3_tags:\n",
    "                a_tag = h3.find('a')\n",
    "                if a_tag and a_tag.get('href'):\n",
    "                    href = a_tag['href']\n",
    "                    full_url = href if href.startswith('http') else urljoin('https://www.elheraldo.co', href)\n",
    "                    article_links.append(full_url)\n",
    "            return article_links\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "                \n",
    "                # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='elheraldo__StyledParagraph-sc-60z8lc-1 dEjMiD article-body__paragraph')\n",
    "            joined_paragraph = ' '.join(p.get_text(strip=True) for p in paragraphs)       \n",
    "        return joined_paragraph\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "92783492-10e3-4173-8419-34a089ebaa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5bb0607-968f-4f4a-b5a8-1beb1c6f90b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: https://www.elheraldo.co/atlantico/\n",
      "finished: https://www.elheraldo.co/deportes/\n",
      "finished: https://www.elheraldo.co/judicial/\n",
      "finished: https://www.elheraldo.co/economia/\n",
      "finished: https://www.elheraldo.co/region/\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f705d35b-8ebb-450b-99f8-76de2621f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Colombia']*len(data),\n",
    "    'FUENTE': ['ElHeraldo']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b283b47b-8e6b-49bb-93ad-6bcbf0dfe25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_ElHeraldo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491748f-7a6f-4523-ac96-4e5ee35ef1ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## El Colombiano (FALTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d29785f-140e-4d41-9c9d-19f1e99c33dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.elcolombiano.com/espana'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df4c611b-17f6-49b1-b26c-d2805b4bc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.elcolombiano.com/espana', 'https://www.elheraldo.co/deportes/', 'https://www.elheraldo.co/judicial/', \n",
    "         'https://www.elheraldo.co/economia/', 'https://www.elheraldo.co/region/']\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <h3> tags with the specified class\n",
    "            h3_tags = soup.find_all(\n",
    "                'h3', \n",
    "                class_='ingl-heading elheraldo__StyledHeadline-sc-1hpknk8-4 kUEUzH ingl-story-card__headline'\n",
    "            )\n",
    "            \n",
    "            for h3 in h3_tags:\n",
    "                a_tag = h3.find('a')\n",
    "                if a_tag and a_tag.get('href'):\n",
    "                    href = a_tag['href']\n",
    "                    full_url = href if href.startswith('http') else urljoin('https://www.elheraldo.co', href)\n",
    "                    article_links.append(full_url)\n",
    "            return article_links\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "                \n",
    "                # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='elheraldo__StyledParagraph-sc-60z8lc-1 dEjMiD article-body__paragraph')\n",
    "            joined_paragraph = ' '.join(p.get_text(strip=True) for p in paragraphs)       \n",
    "        return joined_paragraph\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb09c1af-16a3-4545-a621-dc4ba55d6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h4 class=\"categorie__noticia__metadato\"> <span style=\"background:#006638\"></span> <a href=\"/deportes/futbol\">FÃºtbol</a> </h4>]\n"
     ]
    }
   ],
   "source": [
    "article_links = []\n",
    "response = requests.get(links[0])\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find all <h3> tags with the specified class\n",
    "    h3_tags = soup.find_all(\n",
    "        'h4', \n",
    "        class_='categorie__noticia__metadato'\n",
    "    )\n",
    "    print(h3_tags)\n",
    "    for h3 in h3_tags:\n",
    "        a_tag = h3.find('a')\n",
    "        if a_tag and a_tag.get('href'):\n",
    "            href = a_tag['href']\n",
    "            full_url = href if href.startswith('http') else urljoin('https://www.elcolombiano.com/', href)\n",
    "            \n",
    "            article_links.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d55d869b-730b-4cdb-af0e-e52950dbe910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.elcolombiano.com/deportes/futbol']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74841ae7-ca70-45b4-ac02-952af98850c3",
   "metadata": {},
   "source": [
    "# Argentina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423daa8-f8b7-46ef-ab8d-1dfd6e6bb78a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## La Nación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2914429d-7471-4e74-ba62-4c36420387aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.lanacion.com.ar'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "59c35847-a1bc-4140-8e6b-5add375bf3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.lanacion.com.ar/politica/', 'https://www.lanacion.com.ar/economia/', 'https://www.lanacion.com.ar/sociedad/', \n",
    "         'https://www.lanacion.com.ar/deportes/', 'https://www.lanacion.com.ar/lifestyle/']\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)  # Assuming 'links' is a list and links[0] is a valid URL\n",
    "        tema = url.split('/')[-2]\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all <a> tags on the page\n",
    "            a_tags = soup.find_all('a')\n",
    "            \n",
    "            for a_tag in a_tags:\n",
    "                href = a_tag.get('href')\n",
    "                if href:\n",
    "                    full_url = href if href.startswith('http') else urljoin(links[0], href)\n",
    "                    article_links.append(full_url)\n",
    "            return list(set([x for x in article_links if tema in x ]))\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "        if art_resp.status_code == 200:\n",
    "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
    "                \n",
    "                # Find all <p> tags with class 'paragraph' across the entire page\n",
    "            paragraphs = art_soup.find_all('p', class_='com-paragraph --s')\n",
    "            joined_paragraph = ' '.join(p.get_text(strip=True) for p in paragraphs)       \n",
    "        return joined_paragraph\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b8d19c94-768e-4164-8643-5601c5352502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "finished: https://www.lanacion.com.ar/politica/\n",
      "58\n",
      "finished: https://www.lanacion.com.ar/economia/\n",
      "30\n",
      "finished: https://www.lanacion.com.ar/sociedad/\n",
      "41\n",
      "finished: https://www.lanacion.com.ar/deportes/\n",
      "30\n",
      "finished: https://www.lanacion.com.ar/lifestyle/\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    print(len(urls))\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a01a3989-b5aa-41e7-89fe-6bebb0e4e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Argentina']*len(data),\n",
    "    'FUENTE': ['LaNación']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a539ec-3ace-45f9-b541-b06796c8f3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55f641-b4d7-41d3-9a9e-454d9929b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c30d92da-24a7-4a9b-b7d7-bf75f8e7be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_LaNacion.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5cac4-2a10-4fb0-a33f-3d321bded418",
   "metadata": {},
   "source": [
    "## Pagina 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e50e7fee-38c1-4653-9aaf-da0d7e04656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.pagina12.com.ar'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d98f6b92-ecc6-415a-bb0d-16ffac853d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://www.pagina12.com.ar/secciones/el-pais', 'https://www.pagina12.com.ar/secciones/economia', 'https://www.pagina12.com.ar/secciones/sociedad', \n",
    "         'https://www.pagina12.com.ar/deportes', 'https://www.pagina12.com.ar/secciones/el-mundo', 'https://www.pagina12.com.ar/secciones/ciencia']\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_list_from_tema(url):\n",
    "    try:\n",
    "        article_links = []\n",
    "        response = requests.get(url)  # Assuming 'links' is a list and links[0] is a valid URL\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "            for a_tag in soup.find_all('a', href=True):\n",
    "                href = a_tag['href']\n",
    "                full_url = href if href.startswith('http') else urljoin(links[0], href)\n",
    "        \n",
    "                # Keep only article URLs that match the pattern: domain + numeric ID + hyphen\n",
    "                if re.match(r'https://www\\.pagina12\\.com\\.ar/\\d+-', full_url):\n",
    "                    article_links.append(full_url)\n",
    "\n",
    "            return list(set(article_links))\n",
    "        else:\n",
    "            print(f\"❌ Failed to fetch: {url} (Status: {response.status_code})\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_list_from_tema: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def get_article_text(link):\n",
    "    try:\n",
    "        art_resp = session.get(link, headers=headers, timeout=10)\n",
    "\n",
    "        if art_resp.status_code == 200:\n",
    "            soup = BeautifulSoup(art_resp.text, 'html.parser')  # Parse the response\n",
    "            article_container = soup.find(\"div\", class_=\"article-main-content\")\n",
    "            \n",
    "            if article_container:\n",
    "                paragraphs = article_container.find_all(\"p\")\n",
    "                article_text = \"\\n\\n\".join(p.get_text(strip=True) for p in paragraphs)      \n",
    "        return article_text\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Exception in get_article_text ({link}): {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "363d6465-5b1d-4564-a223-bf48a03ba413",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "finished: https://www.pagina12.com.ar/secciones/el-pais\n",
      "11\n",
      "finished: https://www.pagina12.com.ar/secciones/economia\n",
      "11\n",
      "finished: https://www.pagina12.com.ar/secciones/sociedad\n",
      "26\n",
      "finished: https://www.pagina12.com.ar/deportes\n",
      "11\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/839607-lula-empezara-a-mover-la-agenda-externa-del-mercosur-con-ind): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/839617-jennifer-geerlings-simons-sera-la-primera-mujer-presidenta-d): cannot access local variable 'article_text' where it is not associated with a value\n",
      "finished: https://www.pagina12.com.ar/secciones/el-mundo\n",
      "11\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/591520-especialistas-argentinos-crean-un-robot-capaz-de-descubrir-f): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/775639-el-futuro-de-la-ia-y-su-impacto-en-el-conocimiento-cambiara-): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/818840-la-investigadora-del-conicet-sandra-diaz-entre-las-100-perso): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/689691-china-cientificos-desarrollan-una-capa-de-invisibilidad-como): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/614939-cientificos-del-conicet-descubrieron-una-nueva-especie-de-di): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/593861-el-lado-oscuro-de-las-bebidas-energeticas-por-que-pueden-ser): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/614543-japon-registran-el-momento-en-el-que-nacio-una-isla): cannot access local variable 'article_text' where it is not associated with a value\n",
      "⚠️ Exception in get_article_text (https://www.pagina12.com.ar/752825-la-nasa-confirma-la-existencia-de-tuneles-en-la-luna): cannot access local variable 'article_text' where it is not associated with a value\n",
      "finished: https://www.pagina12.com.ar/secciones/ciencia\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tema in links:\n",
    "    urls = get_list_from_tema(tema)\n",
    "    print(len(urls))\n",
    "    for article in urls:\n",
    "        data.append(get_article_text(article))\n",
    "        time.sleep(random.uniform(1,2))\n",
    "    print(f'finished: {tema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a5c520b2-24f3-4c0d-aad9-eb0770bc82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Argentina']*len(data),\n",
    "    'FUENTE': ['Pagina12']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "71e56980-5ae9-46fc-945b-1827eecb9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_Pagina12.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237c784-bd4b-4eac-a5ec-302a9fc5a01d",
   "metadata": {},
   "source": [
    "# Chile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb63e5-475d-4d0b-b569-269532e97c80",
   "metadata": {},
   "source": [
    "## Diario de Concepción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b699ef5d-6fd8-41b8-818a-f9a757510abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.diarioconcepcion.cl'\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a91c7eb2-0ca0-40b7-abd4-8358bf31b1a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = [\"https://www.diarioconcepcion.cl/search?category=editorial&page={}\", \"https://www.diarioconcepcion.cl/search?category=opinion&page={}\", \n",
    "           \"https://www.diarioconcepcion.cl/search?category=ciudad&page={}\", \"https://www.diarioconcepcion.cl/search?category=politica&page={}\", \"https://www.diarioconcepcion.cl/search?category=economia&page={}\"\n",
    "           , \"https://www.diarioconcepcion.cl/search?category=deportes&page={}\", \"https://www.diarioconcepcion.cl/search?category=cultura&page={}\"]\n",
    "all_links = set()\n",
    "for url in base_url:\n",
    "    x = url.split('=')[1]\n",
    "    x = x.split('&')[0]\n",
    "    for page in range(1, 20):\n",
    "        print(f\"Processing page {page}...\")\n",
    "        response = requests.get(url.format(page))\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            if x in href and href.endswith(\".html\"):\n",
    "                if not href.startswith(\"http\"):\n",
    "                    href = \"https://www.diarioconcepcion.cl\" + href\n",
    "                all_links.add(href)\n",
    "\n",
    "# Convert to sorted list\n",
    "final_links = sorted(all_links)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "eff4c159-f807-4049-a5c9-aca3971bd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(link):\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    all_text = \"  \".join(p.get_text(strip=True) for p in paragraphs[1:-7])\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0489b0a6-efcd-42f8-87ae-6950165ec163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in final_links:\n",
    "    data.append(get_news(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c45306cb-a067-40a9-9327-38bc887fb51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'TEXTO': data,\n",
    "    'PAÍS': ['Chile']*len(data),\n",
    "    'FUENTE': ['DiarioConcepción']*len(data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b1d65-eaae-4505-9840-fd7160ea6e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "56445130-2048-42b9-813c-a12e62c02684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos_DiaioConcepcion.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda902a-1c07-409d-b532-4e9860dec05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
